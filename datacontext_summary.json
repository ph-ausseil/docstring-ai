[
  {
    "file": "./docstring_ai/__init__.py",
    "description": "Operation failed due to an API error."
  },
  {
    "file": "./docstring_ai/lib/config.py",
    "description": "The provided Python code consists of a configuration module primarily responsible for setting constants related to model processing tasks and a logging setup. It facilitates smooth interaction with an external model, handles API requests effectively, implements context storage, and establishes a custom logging configuration with colored outputs. Below is a comprehensive description of its functionalities, purpose, classes, and constructs.\n\n### Purpose of the Module\n\nThe primary purpose of this module is to manage constants for a model-related task processing environment and to provide a logging configuration that enhances debugging and monitoring capabilities. It allows for clear configurations for model interaction while enabling a structured logging mechanism that improves the visibility of runtime activities.\n\n### Main Functionalities\n\n1. **Model Configuration**:\n   - Defines crucial constants that determine how the model interacts with the application, specifying model names, token limits, embedding formats, and retry mechanisms for API requests.\n\n2. **Context Handling**:\n   - Specifies collection names and paths that are used to store and manage context data, allowing for efficient access and retrieval necessary for subsequent data processing tasks.\n\n3. **Custom Logging Setup**:\n   - Implements a custom logging setup featuring colored output based on log severity levels, facilitating easier identification of log messages during operation.\n\n4. **Filtering Unwanted Logs**:\n   - Excludes log messages from specific libraries that may clutter the console, ensuring that the relevant log messages are highlighted while ignoring the noise from lower-priority logs.\n\n### Constants Defined\n\nThe module contains several important constants, each serving a unique purpose:\n\n- **`MODEL` (str)**: Name of the model for processing tasks. Can be changed according to task requirements.\n  \n- **`MAX_TOKENS` (int)**: Maximum allowable tokens in a request to ensure it\u2019s processed without errors.\n  \n- **`EMBEDDING_MODEL` (str)**: Specifies the embedding model to generate numerical vectors from text.\n  \n- **`MAX_RETRIES` (int)**: Maximum API retry attempts to improve resilience against transient errors.\n  \n- **`RETRY_BACKOFF` (int)**: Delay before retrying a failed API request to help manage server load.\n  \n- **`CHROMA_COLLECTION_NAME` (str)**: Defines the name of the ChromaDB collection for storing context data.\n  \n- **`DATA_PATH` (Path)**: Specifies a path for data storage, using the `pathlib.Path` framework for improved path manipulations.\n  \n- **`CACHE_FILE_NAME` (str)**: Filename for caching data to enhance performance by avoiding redundant operations.\n  \n- **`CONTEXT_SUMMARY_PATH` (str)**: Path for storing context summaries, enabling retrieval of important information later.\n  \n- **`DOCSTRING_AI_TAG` (str)**: A commented out tag identifying the source of docstring generation.\n\n### Logging Configuration\n\nThe module implements a custom logging setup using Python's built-in `logging` library. It includes:\n\n#### Classes\n1. **`ColoredFormatter`**:\n   - A custom logging formatter that adds color coding to log messages based on their severity level. \n   - **Attributes**:\n     - `COLOR_MAP`: Maps log levels to color codes for console output.\n     - `RESET`: Used to reset to default console styles.\n   - **Methods**:\n     - `format(self, record)`: Overrides the default format method to include color coding for log levels.\n\n2. **`ExcludeLibrariesFilter`**:\n   - A filter to exclude log messages from specific libraries to reduce log clutter.\n   - **Methods**:\n     - `filter(self, record)`: Checks if the log record\u2019s name starts with any of the excluded modules.\n\n3. **`HTTPRequestFilter`**:\n   - A filter designed to exclude logs specifically containing HTTP request information.\n   - **Methods**:\n     - `filter(self, record)`: Returns false for logs that mention 'HTTP Request:'.\n\n#### Functions\n1. **`setup_logging()`**:\n   - Configures logging for the application, setting up handlers, levels, and filters to manage the output effectively.\n   - Utilizes the custom `ColoredFormatter` for colored outputs and applies filters to suppress irrelevant logs.\n\n### Additional Notes\n\n- **Path Handling**: The use of `pathlib.Path` for paths facilitates cross-platform compatibility and more readable path manipulations.\n- **Debugging and Monitoring**: The logging configuration enhances the ability to debug the application and monitor its activities, making it easier to maintain the application in production.\n- **Performance Optimization**: By utilizing caching and structuring log outputs, the module ensures that the performance of the application is optimized without losing significant context or oversight of processes.\n\n### Conclusion\n\nThis Python module encapsulates essential configurations and logging mechanisms necessary for a robust model interaction environment. It provides a scalable and maintainable structure, allowing developers to adjust constants for different processing tasks easily while ensuring that logging is effective and informative."
  },
  {
    "file": "./docstring_ai/lib/chroma_utils.py",
    "description": "The provided Python code contains a module designed for interacting with a ChromaDB database, specifically for embedding and managing Python file contents, class summaries, and relevant contexts. It employs the OpenAI embedding model to convert text into embeddings and implements logging for monitoring actions and error handling. Below is a comprehensive description of its functionalities, purpose, classes, and function constructors.\n\n### Purpose of the Module\n\nThe primary purpose of this module is to utilize ChromaDB for both storing and retrieving embeddings of Python code files and their associated class summaries. It serves as a bridge for handling file contents, extracting relevant information based on specified user inputs (like class dependencies), and maintaining an organized storage system that is efficient for subsequent retrieval tasks. \n\n### Main Functionalities\n\n1. **ChromaDB Initialization**:\n   - Establishes a connection to the ChromaDB server, allowing further interactions with the database.\n\n2. **Collection Management**:\n   - Checks for existing collections in ChromaDB and creates a new one if it does not exist, ensuring that relevant data is stored efficiently.\n\n3. **Embedding and Storing Files**:\n   - Reads contents of Python files, generates embeddings for the texts, and stores both the embeddings and metadata in ChromaDB.\n\n4. **Context Retrieval**:\n   - Retrieves relevant documents (or contexts) from the collection, ensuring that the total token count does not exceed a predefined threshold.\n\n5. **Summary Storage**:\n   - Embeds and stores summaries for specific classes, making the information easily retrievable for future contextual requirements.\n\n### Function Descriptions\n\n#### 1. `initialize_chroma()`\n\n- **Purpose**: Initializes and returns a ChromaDB client connection.\n- **Returns**: Instance of `chromadb.Client`.\n- **Example Usage**: \n  ```python\n  client = initialize_chroma()\n  ```\n\n#### 2. `get_or_create_collection(client: chromadb.Client, collection_name: str)`\n\n- **Purpose**: Retrieves an existing collection or creates a new one in ChromaDB.\n- **Parameters**:\n  - `client`: The ChromaDB client.\n  - `collection_name`: The name of the collection to interact with.\n- **Returns**: Instance of `chromadb.Collection`.\n- **Exceptions**: Raises an exception if there is an issue retrieving or creating the collection.\n\n#### 3. `embed_and_store_files(collection: chromadb.Collection, python_files: List[str], tags: Dict[str, str] = {})`\n\n- **Purpose**: Reads Python files, embeds their contents, and stores them in the specified ChromaDB collection.\n- **Parameters**:\n  - `collection`: The ChromaDB collection where the documents will be stored.\n  - `python_files`: A list of file paths to the Python files for embedding.\n  - `tags`: Optional metadata tags for enhanced storage information.\n- **Exceptions**: Raises an exception if there are errors reading files or adding them to ChromaDB.\n\n#### 4. `get_relevant_context(collection: chromadb.Collection, classes: List[str], max_tokens: int, where: str = None)`\n\n- **Purpose**: Retrieves context from the collection based on the specified classes while ensuring the total token count remains within a limit.\n- **Parameters**:\n  - `collection`: ChromaDB collection to query.\n  - `classes`: List of class names to retrieve context for.\n  - `max_tokens`: Maximum number of tokens allowed for retrieved context.\n  - `where`: Optional filtering parameter.\n- **Returns**: A string containing the accumulated context.\n- **Exceptions**: Raises exceptions for errors encountered during querying.\n\n#### 5. `store_class_summary(collection: chromadb.Collection, file_path: str, class_name: str, summary: str)`\n\n- **Purpose**: Stores a summary for a specific class in ChromaDB, associating it with the respective file path.\n- **Parameters**:\n  - `collection`: The ChromaDB collection where the summary will be stored.\n  - `file_path`: The file path containing the class.\n  - `class_name`: The name of the class for which the summary is stored.\n  - `summary`: The summary text to embed and store.\n- **Exceptions**: Raises exceptions related to storage issues.\n\n### Logging Configuration\n\nThis module employs logging to capture important events, debug information, and error reports. The logging is set up to provide significant insight into operations, such as:\n\n- File reads and embeddings.\n- Creation of collections and error handling during these processes.\n- Reporting issues related to file paths, duplicate IDs, and empty documents.\n\nThe logging statements (with various levels such as `info` and `error`) help in monitoring the program's execution and making it easier to troubleshoot issues when they arise.\n\n### Exception Handling\n\nThe code includes robust exception handling to ensure graceful error management throughout its operations. Exceptions are caught and logged, making it easier for developers to identify issues without causing application crashes.\n\n### Conclusion\n\nThis Python module provides a well-structured set of functionalities for embedding and managing Python file contents within a ChromaDB environment. It encapsulates important operations such as initializing the database client, managing collections, storing and retrieving context and summaries, and implementing thorough logging for monitoring and debugging purposes. The overall code serves as an effective tool for applications requiring semantic understanding and retrieval of Python code and its class structure."
  },
  {
    "file": "./docstring_ai/lib/utils.py",
    "description": "The provided Python script is a utility that interacts with a Git repository. It includes various functions to manage Python files, interact with version control, create backups, and handle caching. The main functionalities revolve around ensuring that the codebase remains consistent, tracking changes, and safely modifying files. Below is a detailed description of the script's structure, purpose, functionalities, and components.\n\n### Purpose of the Module\n\nThe script is designed to facilitate the management of a Python project's codebase, particularly focusing on:\n\n- Checking the integrity of the Git repository.\n- Ensuring that necessary modifications to the files are done safely and backed up.\n- Providing caching to optimize performance when accessing files.\n- Interacting with Python code files in the repository, ensuring changes are safe from uncommitted modifications.\n\n### Main Functionalities\n\n1. **Source Code Management**:\n   - Ensures that any changes made to files are tracked and properly managed using Git.\n   - Checks for uncommitted changes to prevent accidental overwrites.\n\n2. **File Backup and Caching**:\n   - Creates backups of critical Python files before modifications, allowing for recovery if needed.\n   - Uses a caching mechanism to keep track of files and their states, improving performance on repeated accesses.\n\n3. **File Processing Utilities**:\n   - Retrieves, sorts, and computes hashes for Python files, aiding in various operations that require file management.\n   - Provides a unified diff to compare original and modified code, facilitating version tracking.\n\n### Key Components and Function Descriptions\n\nThe script contains several functions that each serve unique purposes:\n\n#### 1. `ensure_docstring_header(content: str) -> str`\n\n- **Purpose**: Ensures that the provided content has a specific docstring header.\n- **Parameters**: `content`: A string representing the potential code content.\n- **Returns**: Updated content with the docstring header included if it wasn't already present.\n\n#### 2. `file_has_uncommitted_changes(repo_path: str, file_path: str) -> bool`\n\n- **Purpose**: Checks if a specific file in the Git repository has uncommitted changes.\n- **Parameters**: \n  - `repo_path`: Path to the repository.\n  - `file_path`: Path to the file to check.\n- **Returns**: Boolean indicating the presence of uncommitted changes.\n\n#### 3. `prompt_user_confirmation(message: str) -> bool`\n\n- **Purpose**: Prompts the user for a yes/no confirmation through the command line.\n- **Parameters**: `message`: The prompt message displayed to the user.\n- **Returns**: Boolean indicating the user's response.\n\n#### 4. `check_git_repo(repo_path) -> bool`\n\n- **Purpose**: Confirms if the specified directory is a Git repository.\n- **Parameters**: \n  - `repo_path`: Directory path to check.\n- **Returns**: Boolean indicating whether it is a Git repository.\n\n#### 5. `has_uncommitted_changes(repo_path) -> bool`\n\n- **Purpose**: Checks the entire repository for uncommitted changes.\n- **Parameters**: `repo_path`: Path to the repository.\n- **Returns**: Boolean indicating the presence of uncommitted changes across the repository.\n\n#### 6. `load_cache(cache_file: str) -> Dict[str, str]`\n\n- **Purpose**: Loads previously saved cache data from a JSON file.\n- **Parameters**: `cache_file`: Path to the cache file.\n- **Returns**: Dictionary mapping file paths to their respective SHA-256 hashes.\n\n#### 7. `save_cache(cache_file: str, cache: Dict[str, str])`\n\n- **Purpose**: Saves the given cache dictionary to a JSON file.\n- **Parameters**: \n  - `cache_file`: Path to the cache file.\n  - `cache`: The cache dictionary to save.\n\n#### 8. `get_python_files(repo_path: str) -> List[str]`\n\n- **Purpose**: Recursively retrieves all `.py` files within the specified repository.\n- **Parameters**: `repo_path`: Path to the repository.\n- **Returns**: List of Python file paths.\n\n#### 9. `sort_files_by_size(file_paths: List[str]) -> List[str]`\n\n- **Purpose**: Sorts a list of file paths based on their size in ascending order.\n- **Parameters**: `file_paths`: List of file paths to be sorted.\n- **Returns**: Sorted list of file paths.\n\n#### 10. `compute_sha256(file_path: str) -> str`\n\n- **Purpose**: Calculates the SHA-256 hash for the provided file.\n- **Parameters**: `file_path`: Path to the file to hash.\n- **Returns**: The resultant SHA-256 hash as a string.\n\n#### 11. `traverse_repo(repo_path: str, pr_depth: int) -> Dict[int, List[str]]`\n\n- **Purpose**: Categorizes folders in the repository based on their depth relative to the root.\n- **Parameters**: \n  - `repo_path`: Path to the repository.\n  - `pr_depth`: The depth limit for folder categorization.\n- **Returns**: Dictionary mapping depth levels to lists of folder paths.\n\n#### 12. `create_backup(file_path: str)`\n\n- **Purpose**: Creates a timestamped backup of the specified file.\n- **Parameters**: `file_path`: Path of the file to back up.\n\n#### 13. `show_diff(original_code: str, modified_code: str) -> str`\n\n- **Purpose**: Generates a unified diff of the original and modified code, allowing users to see changes.\n- **Parameters**: \n  - `original_code`: Original code as a string.\n  - `modified_code`: Modified code as a string.\n- **Returns**: A formatted string showing the differences.\n\n### Logging\n\nThe script extensively uses logging to provide insights about its operations, including:\n\n- Start and completion of tasks.\n- Any errors encountered during execution, especially in Git operations or file handling.\n- Status updates regarding cache loading/saving, file processing, and repository checks.\n\n### Conclusion\n\nThis Python script serves as a comprehensive tool for managing a codebase in a Git repository. It emphasizes safe practices for modifying Python files, ensures version control hygiene by checking for uncommitted changes, and facilitates user interactions when critical decisions are required. The functionalities regarding file management, caching, and backup creation collectively enhance the usability and safety of working with code in a collaborative environment."
  },
  {
    "file": "./docstring_ai/__main__.py",
    "description": "The provided Python module automates the process of adding docstrings to Python files within a specified Git repository and integrates with GitHub to create pull requests (PRs). It utilizes the OpenAI API for generating docstrings and employs command-line arguments for configuration. This script simplifies documentation tasks and facilitates collaboration via version control.\n\n### Purpose of the Module\n\nThe main goal of this module is to enhance the documentation of Python code by automatically generating docstrings for classes and functions and providing a streamlined method to submit these changes back to a GitHub repository through pull requests. This approach improves code maintainability and readability in collaborative environments.\n\n### Main Functionalities\n\n1. **Docstring Generation**:\n   - Utilizes the OpenAI API to generate docstrings for Python code based on the existing code structure.\n\n2. **GitHub Integration**:\n   - Integrates with GitHub to create a pull request for the changes made in the repository. This includes handling branch creation and PR submission processes.\n\n3. **Command-Line Interface**:\n   - Uses CLI arguments to offer configurable options for various execution parameters, such as paths, GitHub repository details, and API keys.\n\n4. **Error Handling and Confirmation Prompts**:\n   - Implements user prompts for confirmation in critical operations (e.g., PR creation) and handles errors gracefully.\n\n5. **Caching Options**:\n   - Offers options to run without cached values, ensuring that the most up-to-date information is processed.\n\n6. **Environment Setup**:\n   - Uses a `.env` file for loading environment variables (e.g., API keys), allowing flexible configuration management.\n\n### Module Structure and Key Components\n\n#### Import Statements\nThe module imports various libraries required for its operation:\n\n- **`argparse`**: For handling command-line arguments.\n- **`os`, `sys`**: For file and system operations.\n- **`openai`, `chromadb`**: For interacting with the OpenAI API and storing embeddings, respectively.\n- **`datetime`**: For handling date and time operations related to naming branches.\n- **`subprocess`**: For executing shell commands related to Git.\n- **`dotenv`**: For loading environment variables.\n- **`github`**: For interacting with GitHub repositories.\n\n#### Function Definitions\n\n1. **`is_git_repo(folder_path)`**\n   - **Purpose**: Checks if the specified folder is part of a Git repository.\n   - **Parameters**: `folder_path`: The path to the folder.\n   - **Returns**: Boolean indicating if the folder is a Git repository.\n\n2. **`get_remote_url(folder_path)`**\n   - **Purpose**: Retrieves the remote URL of the Git repository.\n   - **Parameters**: `folder_path`: Path to the folder.\n   - **Returns**: The remote URL as a string or `None` if the command fails.\n\n3. **`parse_github_url(remote_url)`**\n   - **Purpose**: Extracts the user and repository name from the GitHub remote URL.\n   - **Parameters**: `remote_url`: The GitHub remote URL.\n   - **Returns**: Tuple with user and repository names or `None` values if parsing fails.\n\n4. **`main()`**\n   - **Purpose**: The primary entry point for the script.\n   - **Functionality**:\n     - Configures the command-line interface and gathers user inputs.\n     - Validates inputs and checks if the specified path exists and is a Git repository.\n     - Prompts for confirmation on critical operations such as PR creation.\n     - Calls the `process_files_and_create_prs` function to manage the core functionality (not defined in the provided code snippet but imported).\n   - **Raises**: `SystemExit` for various error conditions (invalid inputs, missing values).\n\n### Command-Line Arguments\nThe script includes several command-line arguments to customize its behavior:\n\n- **`--path`**: Required path to the repository or folder containing Python files.\n- **`--api_key`**: OpenAI API key, either from the command line or environment variable.\n- **`--pr`**: GitHub repository for PR creation in the format `owner/repo`.\n- **`--github-token`**: GitHub personal access token.\n- **`--branch-name`**: Custom branch name for the PR, automatically generated if not provided.\n- **`--pr-name`**: Custom name for the pull request.\n- **`--pr-depth`**: Depth level for creating PRs per folder.\n- **`--manual`**: Enables manual validation before changes are applied.\n- **`--help-flags`**: Displays descriptions of available flags.\n- **`--no-cache`**: Runs the script without cached values.\n\n### Logging and User Interaction\n- The module employs logging to capture various stages of execution and errors encountered during the process, providing visibility into its internal workings.\n- It includes interactive user prompts for confirmations, particularly when modifying repository content or creating PRs.\n\n### Conclusion\nThis Python module serves as an effective tool for automating the addition of docstrings to Python files and facilitating collaboration through GitHub. By leveraging the OpenAI API and command-line arguments, it provides a flexible and efficient workflow for developers looking to improve code documentation. The integration with GitHub enhances team collaboration by enabling easy reviews and discussions around code changes via pull requests, thereby contributing to better code quality and maintainability in Python projects."
  },
  {
    "file": "./docstring_ai/lib/github_utils.py",
    "description": "The provided Python code defines a module that automates the process of creating pull requests (PRs) in a GitHub repository by adding docstrings to Python files. This module leverages various libraries and functionalities, such as interacting with GitHub's API, managing Git operations, and working with Python files within a specified directory. Below is a comprehensive description of its main components, functionalities, purpose, and structure.\n\n### Purpose of the Module\n\nThe primary purpose of this Python module is to:\n1. Generate unique branches in a GitHub repository for adding docstrings to Python files.\n2. Commit those changes and create a pull request for review and merging.\n3. Ensure that the process is automated, reducing the manual effort required to manage documentation.\n\n### Main Functionalities\n\n1. **Branch Name Sanitization**:\n   - Ensures the generated branch names comply with Git naming conventions by replacing invalid characters.\n\n2. **Unique Branch Creation**:\n   - Generates unique branch names to avoid conflicts with existing branches.\n\n3. **GitHub Pull Request (PR) Creation**:\n   - Automates the Git commands required to create a branch, commit changes, and submit a pull request on GitHub.\n\n4. **Change Detection**:\n   - Identifies which Python files have been modified since the last commit and includes this information in the pull request body.\n\n5. **Error Handling and Logging**:\n   - Implements logging mechanisms to track the state of operations and error handling to report any issues encountered during execution.\n\n6. **File Management**:\n   - Provides functions to retrieve all Python files in a given directory structure.\n\n### Structure of the Code\n\nThe module consists of several function definitions, with each function focusing on a specific aspect of the automation process.\n\n#### Function Descriptions\n\n1. **`sanitize_branch_name(name: str) -> str`**:\n   - **Purpose**: Cleans up the branch name by replacing invalid characters with underscores.\n   - **Parameters**: \n     - `name`: The original branch name.\n   - **Returns**: The sanitized branch name.\n\n2. **`generate_unique_suffix() -> str`**:\n   - **Purpose**: Generates an 8-character unique suffix using UUID4 to append to branch names.\n   - **Returns**: A unique string.\n\n3. **`create_github_pr(repo_path: str, github_token: str, github_repo: str, branch_base_name: str, pr_name: str) -> None`**:\n   - **Purpose**: Creates a pull request by managing GitHub API operations and local git commands.\n   - **Parameters**: \n     - `repo_path`: Path to the local repository.\n     - `github_token`: Access token for GitHub authentication.\n     - `github_repo`: Identifier for the target GitHub repository.\n     - `branch_base_name`: Base name for the new branch.\n     - `pr_name`: Title of the pull request.\n   - **Raises**: \n     - `GithubException`: For issues with the GitHub API.\n     - `subprocess.CalledProcessError`: For git command failures.\n     - `Exception`: For other unexpected errors.\n\n4. **`commit_and_push_changes(repo_path: str, branch_name: str, commit_message: str) -> None`**:\n   - **Purpose**: Handles the git operations to commit and push changes to the specified branch.\n   - **Parameters**: \n     - `repo_path`: Path to the repository.\n     - `branch_name`: Name of the branch to commit changes to.\n     - `commit_message`: Message to use when committing changes.\n   - **Raises**: \n     - `subprocess.CalledProcessError`: For git command failures.\n\n5. **`get_changed_files(repo_path: str, branch_name: str) -> List[str]`**:\n   - **Purpose**: Retrieves a list of changed Python files since the last commit on the specified branch.\n   - **Parameters**: \n     - `repo_path`: Path to the local repository.\n     - `branch_name`: Name of the branch to check against.\n   - **Returns**: List of changed Python file paths.\n\n6. **`get_python_files(repo_path: str) -> List[str]`**:\n   - **Purpose**: Gathers all Python file paths in the specified repository.\n   - **Parameters**: \n     - `repo_path`: Path to the local repository.\n   - **Returns**: List of Python file paths relative to the repository.\n\n### Additional Details\n\n- **Libraries and Imports**: The module uses several libraries, including:\n  - `os`, `sys`, and `shutil`: For file and system operations.\n  - `openai`: To interact with OpenAI's API (though not utilized in the provided code).\n  - `chromadb`: For managing embeddings and context (not actively used in the provided code).\n  - `uuid`: To generate unique identifiers for branch names.\n  - `logging`: For logging events and errors throughout the module.\n  - `GitHub`: A wrapper around the GitHub API to facilitate interactions with GitHub repositories.\n\n- **Subprocess Management**: Many of the Git operations (like `checkout`, `add`, `commit`, etc.) are executed using `subprocess.run`, allowing direct execution of Git commands from within the Python script.\n\n- **Error Checking and Handling**: The code includes error handling that logs failures and raises exceptions as needed, allowing the calling functions or scripts to respond appropriately.\n\n### Conclusion\n\nThis Python module automates the creation of pull requests by managing changes to Python files in a GitHub repository. It streamlines the process, making it easier to maintain documentation through docstrings while leveraging Git for version control. The structure and functionality of the code provide a robust solution for developers looking to enhance their workflow in managing code documentation. Overall, it serves as a valuable tool for improving code quality and fostering collaboration within development teams."
  },
  {
    "file": "./docstring_ai/lib/docstring_utils.py",
    "description": "The provided Python module is designed to automate the extraction and handling of docstrings from Python code. It leverages the OpenAI API and other utilities to enhance code documentation by adding meaningful docstrings and managing Python classes. Below is a comprehensive description of its purpose, functionalities, classes, and key functions.\n\n### Purpose of the Module\n\nThe primary goal of this module is to facilitate:\n1. **Docstring Extraction**: To extract and compile docstrings from Python functions, classes, and modules.\n2. **Class Parsing**: To analyze and retrieve information about Python classes and their parent classes.\n3. **Interfacing with OpenAI**: To use OpenAI's capabilities for generating or augmenting documentation based on the extracted information.\n\n### Main Functionalities\n\n1. **Extracting Descriptions**: Retrieves descriptions from the docstrings of functions, classes, and modules.\n2. **Class Docstring Extraction**: Allows users to get the specific docstring for defined classes within a file.\n3. **Class Structure Parsing**: Parses a Python file to build a dictionary detailing classes and their parent classes.\n4. **Logging and Error Handling**: Implements logging to track the extraction process and errors during execution.\n5. **AST (Abstract Syntax Tree) Utilization**: Uses Python's AST module to programmatically analyze the structure of Python code.\n\n### Key Components\n\n#### Functions\n\n1. **`extract_description_from_docstrings(code_with_docstrings: str) -> str`**:\n   - **Purpose**: Extracts the first line of docstrings from functions, classes, and modules within provided code.\n   - **Parameters**:\n     - `code_with_docstrings`: A string containing the Python code.\n   - **Returns**: A semicolon-separated string of extracted descriptions or an empty string.\n   - **Raises**: Logs an error if parsing fails.\n\n2. **`extract_class_docstring(code: str, class_name: str) -> str`**:\n   - **Purpose**: Extracts the docstring for a specific class using its class name.\n   - **Parameters**:\n     - `code`: Source code as a string.\n     - `class_name`: The name of the class whose docstring is to be extracted.\n   - **Returns**: The class's docstring or an empty string if not found.\n   - **Raises**: Logs an error if extraction fails.\n\n3. **`parse_classes(file_path: str) -> Dict[str, List[str]]`**:\n   - **Purpose**: Parses a given Python file to identify classes and their parent classes.\n   - **Parameters**:\n     - `file_path`: Path to the Python file.\n   - **Returns**: A dictionary with class names as keys and their parent classes in a list as values.\n   - **Raises**: Logs errors during file reading or parsing.\n\n#### Class: `DocstringExtractor`\n\nThis class encapsulates the logic for extracting docstrings and managing imports.\n\n- **`__init__(self, file_path: str)`**:\n  - Initializes the extractor with the path to the target Python file.\n  \n- **`read_file(self) -> None`**:\n  - Reads the file's contents into memory and prepares for parsing.\n  - Raises `FileNotFoundError` or `IOError` if the file cannot be accessed.\n\n- **`parse_ast(self) -> None`**:\n  - Parses the file content into an Abstract Syntax Tree (AST), which represents the code structure.\n  - Raises `SyntaxError` if the code has invalid syntax.\n\n- **`extract_docstrings(self) -> None`**:\n  - Extracts all docstrings from the parsed AST and compiles them into an internal dictionary for easy access.\n\n- **`list_imports_from_package(self, package: str) -> List[str]`**:\n  - Extracts all imports from a specified package, providing insights into imported modules or functions.\n  - Raises `ValueError` if the AST is not parsed.\n\n- **`compile(self) -> str`**:\n  - Compiles the extracted docstrings into a human-readable format for reporting or further processing.\n\n- **`get_docstrings_dict(self) -> Dict[str, Dict[str, str]]`**:\n  - Returns the dictionary containing extracted docstring information.\n\n- **`process(self) -> Dict[str, Dict[str, str]]`**:\n  - Orchestrates the entire extraction process by reading, parsing, and extracting docstrings.\n\n- **`process_imports(self, package: str) -> List[str]`**:\n  - Facilitates the import extraction process, ensuring the file is read and parsed beforehand.\n\n### Logging\n\nThe module uses the Python logging library to track its operations and record important events or errors. The logging level is set to INFO, meaning it will log informational messages, warnings, and errors.\n\n### Context and Structure\n\n1. **Imports**: The module imports various built-in libraries, including `ast` for AST manipulation, `openai` for API interactions, and standard libraries such as `logging`.\n\n2. **Deprecated Notices**: The module contains deprecated function warnings, indicating potential future removals or replacements to guide developers using the module.\n\n3. **Error Handling**: Each function contains try-except blocks to manage errors gracefully and log relevant error messages, aiding debugging and usage tracking.\n\n### Conclusion\n\nThis Python module serves as a powerful tool for improving code documentation in Python projects through automated docstring extraction and analysis. Its ability to parse classes, handle errors effectively, and integrate with the OpenAI API positions it as a critical component for developers seeking to enhance their code's clarity and maintainability. Overall, it brings structure and organization to the often tedious task of managing in-code documentation, allowing developers to focus more on functionality and less on manual documentation."
  },
  {
    "file": "./docstring_ai/lib/prompt_utils.py",
    "description": "The provided Python code is a module designed to manage an AI assistant that helps add comprehensive docstrings to Python code. The assistant utilizes OpenAI's API for generating docstrings based on the context provided, which can be retrieved from a vector store in ChromaDB. The module includes functions to initialize and interact with the assistant, as well as to facilitate communication via threads. Below is a comprehensive breakdown of the module's purpose, functionalities, classes, functions, and key components.\n\n### Purpose of the Module\n\nThe module aims to enhance Python code documentation by automating the addition of docstrings through an AI assistant. It allows developers to easily interact with the assistant to generate docstrings, ensuring clarity and context in the codebase. The integration with ChromaDB provides relevant contextual information to assist the AI in generating accurate and meaningful documentation.\n\n### Main Functionalities\n\n1. **Assistant Initialization**: Initializes or retrieves an existing AI assistant using OpenAI's API.\n2. **Thread Management**: Creates and manages threads to maintain conversational context with the assistant.\n3. **Docstring Generation**: Constructs prompts based on provided code and context, allowing the assistant to generate appropriate docstrings.\n4. **Context Handling**: Retrieves relevant context from ChromaDB to inform the assistant\u2019s responses.\n5. **Code Extraction**: Extracts code blocks from messages received from the assistant to facilitate further processing.\n6. **Error Handling & Logging**: Implements comprehensive error handling and logging for tracking operations and debugging.\n\n### Class and Function Descriptions\n\n#### Classes\n\n1. **`PythonFile` (from Pydantic's BaseModel)**:\n   - **Purpose**: Represents a Python file with an updated script containing new docstrings.\n   - **Attributes**:\n     - `new_file_content`: A string field that holds the updated content of the Python script with added docstrings.\n\n#### Functions\n\n1. **`initialize_assistant(api_key: str, assistant_name: str = \"DocstringAssistant\") -> str`**:\n   - **Purpose**: Initializes a new assistant or retrieves an existing one based on its name.\n   - **Parameters**:\n     - `api_key`: API key for OpenAI authentication.\n     - `assistant_name`: Optional name for the assistant; defaults to \"DocstringAssistant\".\n   - **Returns**: The ID of the assistant or `None` if initialization fails.\n   - **Raises**: Logs errors in case of failure.\n\n2. **`update_assistant_tool_resources(api_key: str, assistant_id: str, file_ids: List[str]) -> None`**:\n   - **Purpose**: Updates the assistant's resources with new file IDs and creates a vector store.\n   - **Parameters**:\n     - `api_key`: API key for authentication.\n     - `assistant_id`: ID of the assistant being updated.\n     - `file_ids`: List of file IDs to add.\n   - **Raises**: Logs errors if the update fails.\n\n3. **`create_thread(api_key: str, assistant_id: str, initial_messages: List[dict] = None) -> str`**:\n   - **Purpose**: Creates a new communication thread for the assistant.\n   - **Parameters**:\n     - `api_key`: API key for authentication.\n     - `assistant_id`: ID of the assistant.\n     - `initial_messages`: Optional list of initial messages for context.\n   - **Returns**: Thread ID or `None` if creation fails.\n   - **Raises**: Logs errors if thread creation fails.\n\n4. **`construct_few_shot_prompt(collection: chromadb.Collection, classes: Dict[str, List[str]], max_tokens: int, context: str = None) -> str`**:\n   - **Purpose**: Constructs a prompt using context summaries and class dependencies.\n   - **Parameters**:\n     - `collection`: ChromaDB collection for context retrieval.\n     - `classes`: Dictionary of class names and dependencies.\n     - `max_tokens`: Maximum tokens allowed for the prompt.\n     - `context`: Optional additional context.\n   - **Returns**: The constructed few-shot prompt.\n   - **Raises**: Logs errors on failures.\n\n5. **`extract_code_from_message(message: str) -> str`**:\n   - **Purpose**: Extracts code blocks formatted in the assistant\u2019s message using regex.\n   - **Parameters**:\n     - `message`: The assistant\u2019s message string.\n   - **Returns**: The extracted code block.\n   - **Raises**: Exception if no code block is found.\n\n6. **`send_message_to_assistant(...)`**:\n   - **Purpose**: Sends a prompt to the assistant and retrieves the response.\n   - **Arguments**: Several parameters for identifying the assistant, thread, and prompt details.\n   - **Returns**: The assistant's response or an error message.\n   - **Raises**: Various exceptions on interaction failures.\n\n7. **`generate_file_description(...)`**:\n   - **Purpose**: Generates a detailed description of a Python file using the assistant.\n   - **Arguments**: Details such as assistant ID, thread ID, and file content.\n   - **Returns**: The detailed description of the file.\n\n8. **`create_file_with_docstring(...)`**:\n   - **Purpose**: Adds docstrings to given Python code using the assistant.\n   - **Arguments**: Assistant ID, thread ID, code content, context, and functions for processing.\n   - **Returns**: The code with added docstrings or `None` if an error occurs.\n\n9. **`create_vector_store(vector_store_name: str, file_ids: List[str]) -> str`**:\n   - **Purpose**: Creates a vector store in OpenAI\u2019s system and associates it with the provided file IDs.\n   - **Arguments**: Name for the vector store and the list of file IDs.\n   - **Returns**: The ID of the created vector store.\n\n10. **`poll_run_completion(run_id: str, thread_id: str, functions: Dict[str, Callable]) -> bool`**:\n    - **Purpose**: Monitors the completion status of a run, with retries handling.\n    - **Arguments**: Run and thread IDs along with any callable functions.\n    - **Returns**: `True` if the run completes successfully, `False` otherwise.\n\n11. **`retrieve_last_assistant_message(thread_id: str) -> str`**:\n    - **Purpose**: Retrieves the last message from a specific thread.\n    - **Arguments**: Thread ID from which to fetch the message.\n    - **Returns**: The last message content or `None`.\n\n### Logging and Error Handling\n\n- The module employs the logging library for tracking operations, debugging, and error reporting. Each function logs relevant information such as successes and failures, which is crucial for maintaining robustness in an interactive AI environment.\n\n### Conclusion\n\nThis Python module serves as an essential component for managing interactions with an AI assistant designed to enhance Python code documentation through automated docstring generation and contextual understanding. The structure allows for easy initialization, prompt construction, and efficient handling of responses, making it a valuable tool for developers seeking to improve code clarity and maintainability. The integration with OpenAI and ChromaDB enables rich contextual processing, positioning the module as a powerful assistant in the software development lifecycle."
  },
  {
    "file": "./docstring_ai/lib/process.py",
    "description": "This Python module is designed to assist in adding docstrings to Python code files using OpenAI's Assistant and integrating with ChromaDB and GitHub for context-aware prompt construction and pull request creation. The module encompasses functionalities to process Python files, manage interactions with the AI Assistant, and handle file uploads and branching for version control.\n\n### Purpose of the Module\n\nThe primary purpose of this module is to:\n1. Process Python files in a specified repository to add detailed docstrings using an AI Assistant.\n2. Utilize vector embeddings from ChromaDB to generate context for the AI's responses.\n3. Create and manage pull requests on GitHub to facilitate the integration of these changes back into the codebase.\n\n### Main Functionalities\n\n1. **Initialization and Configuration**: Sets up environment variables, logging, and necessary configurations.\n2. **GitHub Interaction**: Creates branches and manages pull requests for the added docstrings.\n3. **File Processing**: Reads Python files, checks for changes using SHA-256 hash comparisons, and filters files that need processing.\n4. **Embedding and Storage**: Uploads files to OpenAI, initializes the AI Assistant, and retrieves context summaries from ChromaDB.\n5. **Docstring Generation**: Constructs prompts for the AI Assistant using context information and processes Python files to generate appropriate docstrings.\n6. **Manual Approval and File Updates**: Provides an option for manual review of changes before saving updates to files.\n\n### Key Components\n\n#### Imports\n\nThe module imports various necessary libraries and modules:\n- **Standard Libraries**: `json`, `os`, `logging`, `time`, `datetime`, `tqdm`, etc.\n- **OpenAI API**: For interaction with the AI Assistant.\n- **ChromaDB**: For context management and embedding files.\n- **docstring_ai.lib.utils**: Utility functions for file handling and caching.\n- **docstring_ai.lib.prompt_utils**: For assisting interactions with the AI assistant and constructing prompts.\n- **docstring_ai.lib.chroma_utils**: For managing ChromaDB interactions.\n- **docstring_ai.lib.github_utils**: For GitHub interaction (creating pull requests).\n\n#### Functions\n\n1. **`process_files_and_create_prs(...)`**:\n   - **Purpose**: Processes Python files to add docstrings and creates pull requests if specified.\n   - **Parameters**:\n     - `repo_path`: The path to the Git repository.\n     - `api_key`: The OpenAI API key for authentication.\n     - `create_pr`: A flag indicating whether to create pull requests.\n     - `github_token`: The GitHub API token for authentication.\n     - `github_repo`: The target GitHub repository for pull requests.\n     - `branch_name`: The name of the branch for PR creation.\n     - `pr_name`: The name of the PR.\n     - `pr_depth`: The depth for categorizing folders in the repo.\n     - `manual`: A flag that indicates if manual approval is required for changes.\n   - **Returns**: None, but modifies files and possibly creates pull requests.\n   - **Raises**: Various exceptions during the processing or API calls.\n\n2. **`process_single_file(...)`**:\n   - **Purpose**: Processes an individual Python file to add docstrings and update context summaries.\n   - **Parameters**: Several parameters including `python_file_path`, `repo_path`, `assistant_id`, etc.\n   - **Returns**: None.\n   - **Function Flow**: Reads the file, checks for caching, constructs the few-shot prompt, generates docstrings using the assistant, and either saves the file or prompts for manual approval.\n\n3. **`filter_files_by_hash(...)`**:\n   - **Purpose**: Filters the list of files based on their SHA-256 hashes and the provided cache.\n   - **Parameters**: List of file paths, the repository path, and cache dictionary.\n   - **Returns**: A list of file paths that require processing.\n\n4. **`upload_files_to_openai(...)`**:\n   - **Purpose**: Uploads Python files to OpenAI for processing and returns the file IDs.\n   - **Parameters**: List of file paths to upload.\n   - **Returns**: List of file IDs received after the upload.\n\n5. **Additional functions**: The module also contains utility functions to handle specific tasks such as `create_github_pr`, implementations for processing contexts and embeddings, and auxiliary functions that enhance the processing workflow.\n\n### Logging and Error Handling\n\nThe module utilizes Python's logging framework to track operational flow and errors, which aids in debugging and user information. Each function logs significant events and errors to ensure that any issues can be traced easily. \n\n### Context and Structure\n\n- The module is structured as a procedural script with clear comments delineating each logical section, including initialization, file processing, and finalization.\n- It leverages utility functions organized in various submodules, promoting modular programming practices and code reuse.\n- The use of a threaded process for interaction with the OpenAI Assistant enhances the user experience, providing contextually relevant responses based on user input.\n\n### Conclusion\n\nThis Python module effectively integrates multiple advanced technologies, including OpenAI's API and ChromaDB, to automate the process of adding docstrings to Python code within a GitHub repository. It facilitates a streamlined workflow for enhancing documentation, ensuring that code is easy to understand and maintain. By automating routine documentation tasks, developers can focus on the development aspects of coding, thus improving overall productivity and code quality."
  }
]