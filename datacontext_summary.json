[
  {
    "file": "./docstring_ai/__init__.py",
    "description": "Operation failed due to an API error."
  },
  {
    "file": "./docstring_ai/lib/config.py",
    "description": "The provided Python file serves as a configuration and logging utility for an application that involves model processing tasks, particularly those related to natural language processing and embeddings. Here\u2019s a comprehensive breakdown of its components, including functionalities, purpose, classes, and function constructors.\n\n### Overview\n\nThis file includes two main sections: one for defining constants related to the application\u2019s model configuration, and the second part focuses on logging utilities, including a custom logging formatter, filters for log messages, and a logging setup function. \n\n### Main Functionalities\n\n1. **Constants Definition**: The first part of the file establishes constants that configure the model's behavior and operational parameters, such as the model name, token limits, retry strategies, and cache file paths.\n  \n2. **Logging Configuration**: The second part deals with configuring the logging mechanism, providing utilities to manage how log messages are formatted and filtered. This ensures clear visibility into the application's operations while avoiding clutter from unnecessary messages.\n\n### Constants Defined\n\n- **`MODEL` (str)**: Specifies the model to be used for processing tasks. Currently, it is set to \"gpt-4o-mini\".\n  \n- **`MAX_TOKENS` (int)**: Denotes the maximum number of tokens (64000) that can be included in a request to the model, helping manage input size for processing tasks.\n\n- **`EMBEDDING_MODEL` (str)**: Indicates the embedding model to be used\u2014\"text-embedding-3-large\"\u2014for generating numerical representations of text input.\n\n- **`MAX_RETRIES` (int)**: The maximum number of times API requests will be retried (set to 5) in the event of transient failures, enhancing the application\u2019s resilience.\n\n- **`RETRY_BACKOFF` (int)**: The time, in seconds, to wait before retrying after an API request failure, set at 5 seconds to manage server load effectively.\n\n- **`CHROMA_COLLECTION_NAME` (str)**: Defines the collection name \"python_file_contexts\" used within ChromaDB for storing relevant context data.\n\n- **`DATA_PATH` (Path)**: A `Path` object set to './data/', designating where data-related files are stored.\n\n- **`CACHE_FILE_NAME` (str)**: Specifies the filename for caching purposes, facilitating efficient data storage and retrieval.\n\n- **`CONTEXT_SUMMARY_PATH` (str)**: The file path for storing summaries of context data necessary for processing tasks.\n\n- **`DOCSTRING_AI_TAG` (str)**: Provides a comment indicating that the docstring was generated by a specified automated tool.\n\n### Logging Configuration\n\nThe logging section of the code defines several components:\n\n#### Classes\n\n1. **`ColoredFormatter`**: \n   - **Purpose**: A custom logging formatter that adds color coding to log messages based on severity levels. \n   - **Components**:\n     - `COLOR_MAP`: A dictionary mapping logging levels to specific colors.\n     - `format`: A method that applies the color based on the log level to enhance log readability.\n\n2. **`ExcludeLibrariesFilter`**: \n   - **Purpose**: A logging filter designed to suppress logs originating from specified modules, preventing clutter in log output.\n   - **Method**:\n     - `filter`: Checks whether the log record's name starts with any of the excluded module prefixes.\n\n3. **`HTTPRequestFilter`**: \n   - **Purpose**: Suppresses logs related to HTTP requests.\n   - **Method**:\n     - `filter`: Excludes log records that contain 'HTTP Request:' in their messages.\n\n#### Functions\n\n1. **`setup_logging()`**:\n   - **Purpose**: Configures the logging setup for the application.\n   - **Components**:\n     - Initializes a `ColoredFormatter` to make log output more readable.\n     - Sets up a console logging handler with the defined formatter.\n     - Configures the logging system to suppress logs from certain libraries to avoid noise in the log output.\n     - Applies the previously defined filters (`ExcludeLibrariesFilter` and `HTTPRequestFilter`) to further refine log output.\n\n### Conclusion\n\nIn summary, this Python file serves as a foundational component for a natural language processing application by defining essential constants for model interactions and implementing a sophisticated logging mechanism. The clear organization of constants and robust logging configuration enhances maintainability and usability, allowing developers to manage model settings and verbose logging effectively. This modular approach aids in easier adaptation of the code as requirements evolve."
  },
  {
    "file": "./docstring_ai/lib/chroma_utils.py",
    "description": "The provided Python file encapsulates a set of functionalities for interacting with ChromaDB, focusing on embedding and storing Python file contents, managing collections, and retrieving relevant context based on class dependencies. Below is a detailed description of the code, highlighting its main functionalities, purpose, classes, and function constructors.\n\n### Overview\n\nThis file is designed to facilitate the process of embedding Python code files, storing them in a database for easy retrieval, and providing functionalities to query context based on specific class dependencies. It uses several libraries, including OpenAI for embeddings, ChromaDB for storage, and logging for monitoring operations.\n\n### Main Functionalities\n\n1. **ChromaDB Initialization**: Establishes a connection to a ChromaDB server instance.\n  \n2. **Collection Management**: Allows retrieval or creation of collections within the ChromaDB database.\n\n3. **File Embedding and Storage**: Reads Python files, embeds their contents, and stores the embeddings alongside metadata in the specified collection.\n\n4. **Context Retrieval**: Queries the stored embeddings based on specified class names and retrieves relevant contextual information without surpassing token limits.\n\n5. **Class Summary Storage**: Stores summarized information about classes within the collections, allowing for improved future retrieval of context about different class dependencies.\n\n### Functions Defined\n\n1. **`initialize_chroma()`**:\n   - **Purpose**: Initializes and returns a ChromaDB client connected to the database.\n   - **Returns**: An instance of `chromadb.Client`.\n   - **Example Usage**: `client = initialize_chroma()`\n\n2. **`get_or_create_collection(client: chromadb.Client, collection_name: str)`**:\n   - **Args**:\n     - `client`: The ChromaDB client instance.\n     - `collection_name`: The name of the collection to be retrieved or created.\n   - **Returns**: The corresponding ChromaDB collection instance.\n   - **Raises**: Exception if there is an issue in collection retrieval or creation.\n   - **Functionality**: Checks if the collection exists; if not, it creates it with the necessary embedding configuration using OpenAI's embedding functions.\n\n3. **`embed_and_store_files(collection: chromadb.Collection, python_files: List[str], tags: Dict[str, str] = {})`**:\n   - **Args**:\n     - `collection`: The target ChromaDB collection for storing documents.\n     - `python_files`: List of file paths to be embedded and stored.\n     - `tags`: Optional metadata tags associated with the files.\n   - **Raises**: Exception if there\u2019s an issue with file reading or storage.\n   - **Functionality**: Reads each Python file, embeds its content, and stores the embeddings in the specified collection. Includes validation checks for data quality (e.g., ensuring unique IDs and non-empty documents).\n\n4. **`get_relevant_context(collection: chromadb.Collection, classes: List[str], max_tokens: int, where: str = None) -> str`**:\n   - **Args**:\n     - `collection`: The ChromaDB collection to query.\n     - `classes`: A list of class dependencies to query.\n     - `max_tokens`: Maximum token count for the context.\n     - `where`: Optional filtering criterion for the query.\n   - **Returns**: A string containing the accumulated context.\n   - **Functionality**: Compiles relevant documents from the collection based on provided class names while ensuring the total token count does not exceed the specified limit.\n\n5. **`store_class_summary(collection: chromadb.Collection, file_path: str, class_name: str, summary: str) -> None`**:\n   - **Args**:\n     - `collection`: The ChromaDB collection where the summary will be stored.\n     - `file_path`: Path to the file containing the class.\n     - `class_name`: Name of the class for which summary is stored.\n     - `summary`: The summary text to embed and store.\n   - **Raises**: Exception if there\u2019s an error storing the class summary.\n   - **Functionality**: Embeds the class summary and associates it with the class and file path, storing it in the collection.\n\n### Logging and Error Handling\n\nThe code handles errors gracefully by using `try` and `except` blocks, logging error messages, and printing stack traces using `traceback.format_exc()`. It employs the standard logging module to log operations, providing insights into the application process and troubleshooting any issues effectively.\n\n### Conclusion\n\nIn summary, this Python file provides a comprehensive framework for managing Python file embeddings with ChromaDB, allowing for easy storage, retrieval, and organization of context based on class dependencies. It combines robust functionality for database interaction with an emphasis on error handling and logging, making it a functional component in applications that leverage data retrieval and natural language processing based on class-level information. This structure not only enhances modularity but also separates embedding and storage logic, facilitating easier future enhancements and maintenance."
  },
  {
    "file": "./docstring_ai/lib/utils.py",
    "description": "The provided Python file implements a suite of utilities primarily aimed at managing Python projects stored in Git repositories. It performs various operations, including ensuring documentation consistency, checking Git status, loading and saving cached data, and managing file modifications. Let's delve into the details of its functionalities, purpose, classes, and function constructors.\n\n### Overview\n\nThis script serves as a utility for Python development, particularly focusing on:\n- Managing documentation through autogenerated docstrings.\n- Interfacing with Git to check for uncommitted changes and validate repository status.\n- Computing file hashes for tracking modifications.\n- Backing up files and displaying code differences.\n- Loading and saving a cache that keeps track of processed files.\n\n### Main Functionalities\n\n1. **Documentation Consistency**: Ensures that files contain a specific docstring header for consistency in the codebase.\n  \n2. **Git Repository Management**: \n   - **Check repository status**: Verifies whether the directory is a valid Git repository.\n   - **Uncommitted changes**: Checks for unsaved changes in the files before allowing further operations.\n\n3. **File and Cache Management**:\n   - **File handling**: Recursively finds Python files in the repository and sorts them by size.\n   - **Hashing**: Computes SHA-256 hashes for files to manage their versions.\n   - **Backup creation**: Creates timestamps of files to prevent data loss.\n   - **Cache loading and saving**: Manages a cache that tracks processed files, improving efficiency.\n\n4. **Code Modification Visualization**: Displays differences between original and modified code using a unified diff format.\n\n### Functions Defined\n\n1. **`ensure_docstring_header(content: str) -> str`**:\n   - **Purpose**: Ensures that the given content includes a predefined docstring tag.\n   - **Returns**: Updated content with the docstring header if missing.\n\n2. **`file_has_uncommitted_changes(repo_path: str, file_path: str) -> bool`**:\n   - **Purpose**: Checks if a specific file in the repository has uncommitted changes by running a Git command.\n   - **Returns**: `True` or `False` indicating the presence of changes.\n\n3. **`prompt_user_confirmation(message: str) -> bool`**:\n   - **Purpose**: Prompts the user for a yes/no confirmation.\n   - **Returns**: `True` if the user confirms; `False` otherwise.\n\n4. **`check_git_repo(repo_path: str) -> bool`**:\n   - **Purpose**: Validates if the specified path is a Git repository.\n   - **Returns**: `True` if the path is a Git repo; otherwise `False`.\n\n5. **`has_uncommitted_changes(repo_path: str) -> bool`**:\n   - **Purpose**: Checks for any uncommitted changes in the Git repository and prompts the user.\n   - **Returns**: `True` if there are changes; if confirmed by the user, it continues.\n\n6. **`load_cache(cache_file: str) -> Dict[str, str]`**:\n   - **Purpose**: Loads a JSON cache file mapping file paths to their SHA-256 hashes.\n   - **Returns**: A dictionary representing the cache.\n\n7. **`save_cache(cache_file: str, cache: Dict[str, str])`**:\n   - **Purpose**: Saves the current cache dictionary to a JSON file.\n\n8. **`get_python_files(repo_path: str) -> List[str]`**:\n   - **Purpose**: Recursively retrieves all Python (`.py`) files from the specified repository path.\n   - **Returns**: A list of paths to Python files.\n\n9. **`sort_files_by_size(file_paths: List[str]) -> List[str]`**:\n   - **Purpose**: Sorts the given list of file paths by their file sizes.\n   - **Returns**: Sorted list of file paths.\n\n10. **`compute_sha256(file_path: str) -> str`**:\n    - **Purpose**: Computes the SHA-256 hash for the specified file.\n    - **Returns**: The hash as a hexadecimal string.\n\n11. **`traverse_repo(repo_path: str, pr_depth: int) -> Dict[int, List[str]]`**:\n    - **Purpose**: Categorizes folders in the repository based on their depth relative to the specified path.\n    - **Returns**: A dictionary mapping depth levels to lists of folder paths.\n\n12. **`create_backup(file_path: str)`**:\n    - **Purpose**: Creates a backup of the specified file with a timestamp, preventing overwrites of previous backups.\n\n13. **`show_diff(original_code: str, modified_code: str) -> str`**:\n    - **Purpose**: Generates a unified diff between two code versions.\n    - **Returns**: A string representing the differences.\n\n### Logging and Error Handling\n\nThe script utilizes the built-in `logging` module to provide feedback to the user, including:\n- Informational messages about the operations being carried out (e.g., loading caches, committing changes).\n- Warnings when issues are detected (e.g., uncommitted changes present).\n- Errors logged in cases where operations fail, such as checking Git status or loading files.\n\n### Conclusion\n\nIn essence, this Python script serves as a utility toolkit for Python developers working within Git repositories. Its focus on ensuring code documentation consistency, automating version control checks, managing files effectively, and providing backup capabilities makes it a valuable tool for development workflows. The modular design allows for straightforward enhancements and integration into broader development ecosystems."
  },
  {
    "file": "./docstring_ai/__main__.py",
    "description": "The Python file provided is a comprehensive script that automates the process of adding docstrings to Python files in a repository and integrates with GitHub to create pull requests (PRs) using OpenAI's API for docstring generation. The script utilizes various libraries and functionalities for handling command-line inputs, interacting with Git repositories, and managing files efficiently. Below is a detailed description of its functionalities, purpose, classes, functions, and overall structure.\n\n### Overview\n\nThis module is designed to enhance the documentation process in Python projects by:\n- Automating the addition of docstrings to Python classes and functions.\n- Integrating with GitHub to facilitate the creation of pull requests after modifications.\n- Utilizing OpenAI's API to generate human-like docstrings, improving code readability and documentation quality.\n\n### Main Functionalities\n\n1. **Docstring Generation**: Connects to OpenAI's API to generate appropriate docstrings for Python files.\n   \n2. **Git Repository Interaction**: Checks if a directory is a Git repository and retrieves the remote URL for integration with GitHub.\n\n3. **Command-Line Interface (CLI)**: Utilizes `argparse` to handle various configuration options provided by the user via command-line arguments.\n\n4. **File System Management**: Processes Python files to insert docstrings, handles caching, and provides feedback to the user for actions taken.\n\n5. **GitHub Pull Requests**: Automatically prepares and submits PRs to a specified GitHub repository after making changes to the Python files.\n\n6. **User Interactivity**: Prompts users for confirmation during critical stages, such as running without PR creation or overriding cache files.\n\n### Key Functions Defined\n\n1. **`is_git_repo(folder_path)`**:\n   - **Purpose**: Checks if the given folder path is a valid Git repository.\n   - **Returns**: `True` if it's a Git repository; otherwise `False`.\n\n2. **`get_remote_url(folder_path)`**:\n   - **Purpose**: Fetches the remote URL of the Git repository from the specified folder.\n   - **Returns**: The remote URL or `None` if there\u2019s an error.\n\n3. **`parse_github_url(remote_url)`**:\n   - **Purpose**: Extracts the user and repository name from the GitHub remote URL.\n   - **Returns**: Tuple containing user and repository names.\n\n4. **`main()`**:\n   - **Purpose**: Serves as the entry point of the script, orchestrating argument parsing, validation, and the overall flow of the script.\n   - **Functionality**:\n     - Parses command-line arguments for configuration.\n     - Validates user inputs and handles cache management.\n     - Determines if a PR is needed and prompts user interactions as necessary.\n     - Calls the processing function (`process_files_and_create_prs`) to generate docstrings and handle GitHub integration.\n\n### Command-Line Arguments\n\nThe script accepts various command-line arguments to customize its behavior:\n- `--path`: Required; specifies the path to the repository or folder containing Python files.\n- `--api_key`: Optional; overrides the OpenAI API key from an environment variable.\n- `--pr`: Optional; specifies the GitHub repository for PR creation.\n- `--github-token`: Optional; GitHub personal access token, with a fallback to an environment variable.\n- `--branch-name`: Optional; names the branch for the PR (auto-generated if not provided).\n- `--pr-name`: Optional; custom name for the pull request.\n- `--pr-depth`: Optional; depth level for traversing folders to create PRs, default is 2.\n- `--manual`: Optional; enables manual validation before applying changes.\n- `--help-flags`: Shows descriptions of available flags.\n- `--no-cache`: Executes without cached values.\n\n### Error Handling and Logging\n\n- The script includes error handling, particularly during Git operations and API interaction. It uses logging to inform the user of the current actions and potential issues encountered during execution.\n- The `setup_logging()` function initializes logging settings, which are useful for debugging and informing users about the status of operations.\n\n### Conclusion\n\nThis Python script acts as a powerful tool for developers looking to enhance their Python codebases by automating the addition of docstrings and the management of GitHub pull requests. By integrating OpenAI's language model, it ensures that generated documentation is of high quality, further improving code readability and maintainability. The design is modular, allowing for easy extensions or modifications, making it a valuable resource for Python development teams."
  },
  {
    "file": "./docstring_ai/lib/github_utils.py",
    "description": "The provided Python file serves as a utility for creating GitHub pull requests (PRs) that automatically add docstrings to Python files within a Git repository. It incorporates several functions that facilitate interacting with Git, managing branches, and communicating with the GitHub API. Here's a comprehensive breakdown of this file, highlighting its main functionalities, purpose, functions, and structure.\n\n### Overview\n\nThe primary goal of this module is to automate the documentation process by:\n- Creating unique branches for docstring updates.\n- Committing changes to those branches.\n- Pushing the branches to a GitHub repository.\n- Generating pull requests with details about the modified files.\n\n### Main Functionalities\n\n1. **Branch Naming**: Ensures that branches are named according to valid Git naming conventions, replacing illegal characters.\n\n2. **Unique Suffix Generation**: Creates unique identifiers for branch names to prevent conflicts.\n\n3. **GitHub Pull Request Creation**: Automates the process of creating a pull request within the specified repository after adding docstrings.\n\n4. **Git Operations**: Manages various Git operations, including checking out branches, committing changes, and pushing to remote branches.\n\n5. **File Management**: Retrieves lists of changed Python files and all Python files in the repository.\n\n### Key Functions Defined\n\n1. **`sanitize_branch_name(name: str) -> str`**:\n   - **Purpose**: Cleans up the branch name by replacing invalid characters with underscores and replacing slashes with dashes.\n   - **Returns**: A sanitized branch name suitable for Git.\n\n2. **`generate_unique_suffix() -> str`**:\n   - **Purpose**: Generates a unique suffix using UUID4 to append to branch names.\n   - **Returns**: An 8-character unique suffix.\n\n3. **`create_github_pr(repo_path: str, github_token: str, github_repo: str, branch_base_name: str, pr_name: str) -> None`**:\n   - **Purpose**: Creates a pull request on GitHub.\n   - **Args**:\n     - `repo_path`: Path to the local GitHub repository.\n     - `github_token`: Personal access token for GitHub.\n     - `github_repo`: Repository identifier (e.g., 'owner/repo').\n     - `branch_base_name`: Base name for the new branch.\n     - `pr_name`: Title for the pull request.\n   - **Functionality**: Creates a new branch based on the default branch, commits changes to it, and then creates the pull request.\n\n4. **`commit_and_push_changes(repo_path: str, branch_name: str, commit_message: str) -> None`**:\n   - **Purpose**: Commits and pushes changes to the specified branch in the local repository.\n   - **Args**:\n     - `repo_path`: Local path to the repository.\n     - `branch_name`: Name of the target branch.\n     - `commit_message`: Message for the commit.\n   - **Functionality**: Performs checkouts, staging, and commits using Git.\n\n5. **`get_changed_files(repo_path: str, branch_name: str) -> List[str]`**:\n   - **Purpose**: Retrieves a list of changed Python files in the branch.\n   - **Args**:\n     - `repo_path`: Path to the local repository.\n     - `branch_name`: Name of the branch to compare against.\n   - **Returns**: A list of changed Python file paths since the last commit.\n\n6. **`get_python_files(repo_path: str) -> List[str]`**:\n   - **Purpose**: Collects all Python (*.py) files in the specified repository.\n   - **Returns**: A list of paths to all Python files relative to the repository's root.\n\n### Structure and Intents\n\n- **Imports**: The script imports various libraries required for operations, including `os`, `openai`, and `subprocess`, among others for Git and GitHub API interactions.\n  \n- **Logging**: The script uses the `logging` module to provide feedback during execution, which is useful for debugging and user information.\n\n- **Error Handling**: Functions often include error handling to manage exceptions related to Git operations or GitHub API calls, ensuring robust performance even in failure scenarios.\n\n### Conclusion\n\nIn summary, this Python module is a well-structured utility designed for enhancing the documentation of Python code by automating the process of adding docstrings and integrating seamlessly with GitHub through pull requests. It provides essential functions for managing branches, committing changes, and creating PRs, all while ensuring the process is as user-friendly as possible. With its focus on functionality, error handling, and logging, this script will be beneficial for developers looking to improve documentation within their Python projects effectively."
  },
  {
    "file": "./docstring_ai/lib/docstring_utils.py",
    "description": "The provided Python module focuses on extracting and managing docstrings from Python code. It incorporates functionalities to interact with OpenAI\u2019s API and facilitate the natural language processing required to enhance code documentation. Below is a comprehensive description of the code, highlighting its main functionalities, purpose, classes, and function constructors.\n\n### Overview\n\nThis module is designed to:\n- Extract descriptions and docstrings from Python classes and functions.\n- Use OpenAI's Assistant to generate appropriate docstrings where they are missing.\n- Parse Python files to identify classes and their parent classes.\n- Handle logging for errors and operations encountered during execution.\n\n### Main Functionalities\n\n1. **Docstring Extraction**: Extracts the first line of docstrings from functions, classes, and modules to provide concise descriptions.\n  \n2. **Class Docstring Retrieval**: Extracts detailed docstrings specifically for a given class by its name.\n  \n3. **Class Parsing**: Parses a Python file to extract class definitions and their parent classes, returning them in a structured dictionary format.\n\n4. **OpenAI Integration**: While the provided module does not include the direct implementation for sending requests to OpenAI, it sets the context for potentially integrating such functionality, given the module\u2019s aim.\n\n5. **Logging**: Tracks the progress and potential issues using Python\u2019s logging module.\n\n### Functions and Classes Defined\n\n#### Functions\n\n1. **`extract_description_from_docstrings(code_with_docstrings: str) -> str`**:\n   - **Purpose**: Extracts a simple description from the docstrings of the provided Python code.\n   - **Arguments**: Takes a string containing Python code with docstrings.\n   - **Returns**: A semicolon-separated string of the extracted descriptions.\n   - **Exceptions**: Raises an exception if there is an error during parsing.\n\n2. **`extract_class_docstring(code: str, class_name: str) -> str`**:\n   - **Purpose**: Retrieves the docstring of a specified class.\n   - **Arguments**: Takes code as a string and the class name as a string.\n   - **Returns**: The docstring of the specified class or an empty string if not found.\n   - **Exceptions**: Raises an exception if an error occurs during extraction.\n\n3. **`parse_classes(file_path: str) -> Dict[str, List[str]]`**:\n   - **Purpose**: Parses a Python file to identify classes and their parent classes.\n   - **Arguments**: A path to the Python file.\n   - **Returns**: A dictionary mapping class names to their corresponding parent classes.\n   - **Exceptions**: Raises an exception if an error occurs during file reading or parsing.\n\n#### Class: `DocstringExtractor`\n\n1. **`__init__(self, file_path: str)`**:\n   - **Purpose**: Initializes the extractor with the path to the Python file to analyze.\n   - **Attributes**: Sets up paths, file contents, an empty AST tree, and dictionaries for docstrings and imports.\n\n2. **`read_file(self) -> None`**:\n   - **Purpose**: Reads the content of the specified Python file.\n   - **Exceptions**: Raises `FileNotFoundError` or `IOError` if there are issues accessing the file.\n\n3. **`parse_ast(self) -> None`**:\n   - **Purpose**: Parses the file content into an Abstract Syntax Tree (AST).\n   - **Exceptions**: Raises `SyntaxError` if the code is invalid or `ValueError` if the file content is not set.\n\n4. **`extract_docstrings(self) -> None`**:\n   - **Purpose**: Extracts all docstrings from the AST and populates the docstrings dictionary, organizing them by type (class, function, module).\n   - **Exceptions**: Raises a `ValueError` if called without a parsed AST.\n\n5. **`list_imports_from_package(self, package: str) -> List[str]`**:\n   - **Purpose**: Extracts and lists all names imported from a specified package within the Python script.\n   - **Arguments**: Name of the package to extract imports from.\n   - **Returns**: A list of names imported from that package.\n   - **Exceptions**: Raises a `ValueError` if the AST is not parsed.\n\n6. **`compile(self) -> str`**:\n   - **Purpose**: Compiles extracted docstrings into a readable format.\n   - **Returns**: A string of the compiled docstrings.\n\n7. **`get_docstrings_dict(self) -> Dict[str, Dict[str, str]]`**:\n   - **Purpose**: Returns the dictionary containing extracted docstrings.\n   - **Returns**: The dictionary mapping element names to types and docstrings.\n\n8. **`process(self) -> Dict[str, Dict[str, str]]`**:\n   - **Purpose**: High-level method to perform the complete docstring extraction process.\n   - **Returns**: The dictionary of extracted docstrings.\n   \n9. **`process_imports(self, package: str) -> List[str]`**:\n   - **Purpose**: High-level method to process import extraction for a specified package.\n   - **Arguments**: Name of the package.\n   - **Returns**: A list of names imported from that package.\n\n### Logging Configuration\n\nAt the start of the module, the logging is configured to display information and debugging messages. This feature is critical for tracking executions and errors encountered during the parsing and extraction processes.\n\n### Conclusion\n\nIn summary, this module is a comprehensive tool designed for automating the extraction of docstring information and parsing Python code structures. It leverages Python's AST libraries to analyze code while providing a structure for potential integration with OpenAI's services for enhancing documentation. With its focus on error handling, logging, and providing structured output, this module is pivotal in maintaining effective and accurate code documentation practices."
  },
  {
    "file": "./docstring_ai/lib/prompt_utils.py",
    "description": "Operation failed due to an API error."
  },
  {
    "file": "./docstring_ai/lib/process.py",
    "description": "The provided Python code is a comprehensive module designed to process Python files for adding docstrings, leveraging OpenAI's AI Assistant, embedding the files in a ChromaDB database, and managing pull requests (PRs) on GitHub. This functionality is structured to facilitate automated documentation practices, enhancing code readability and maintainability.\n\n### Overview\n\nThe purpose of this module is twofold:\n1. To integrate AI-driven docstring generation into the Python code base, improving documentation with the help of OpenAI's Assistant.\n2. To manage files effectively by embedding relevant context into a database and submitting changes to GitHub through pull requests.\n\n### Main Functionalities\n\n1. **File Processing**: Processes Python files to identify functions, classes, and methods requiring docstrings.\n2. **Docstring Generation**: Uses OpenAI's API to generate appropriate docstrings based on the context of the code.\n3. **Persistent Data Management**: Embeds information into ChromaDB and updates GitHub with changes via pull requests.\n4. **Error and Cache Management**: Manages uncommitted changes, checks the status of files, and integrates with utilities to handle caches efficiently.\n\n### Key Functions Defined\n\n1. **`process_files_and_create_prs(...)`**:\n   - **Purpose**: The main function of this module that orchestrates the processing of Python files to add docstrings and manage pull requests.\n   - **Arguments**:\n     - `repo_path`: The local path of the Git repository.\n     - `api_key`: The OpenAI API key.\n     - `create_pr`: Flag indicating if pull requests should be created.\n     - `github_token`: GitHub token for authentication.\n     - `github_repo`: Specify the GitHub repository to submit pull requests.\n     - `branch_name`: Name of the new branch for the pull request.\n     - `pr_name`: Title of the pull request.\n     - `pr_depth`: Maximum depth for categorization in the repository.\n     - `manual`: Indicates if manual approval is required before changes are made.\n   - **Returns**: None (performs its operations directly).\n   - **Functionality**:\n     - Initializes the API keys and checks the Git repository status.\n     - Loads and processes Python files, including embedding and caching.\n     - Initializes an OpenAI Assistant for generating docstrings.\n     - Creates pull requests on GitHub if specified.\n\n2. **`process_single_file(...)`**:\n   - **Purpose**: Processes each individual Python file, updating its docstrings, handling manual approval if necessary, and updating cache information.\n   - **Arguments**:\n     - `python_file_path`: The path to the Python file.\n     - `repo_path`: Path of the Git repository.\n     - `assistant_id`: The ID for the OpenAI Assistant.\n     - `thread_id`: The thread ID used for interactions with the Assistant.\n     - `collection`: ChromaDB collection instance.\n     - `context_summary`: Summary of contexts previously generated.\n     - `cache`: Manual cache of file states.\n     - `manual`: Boolean flag for manual intervention.\n   - **Returns**: None.\n   - **Functionality**:\n     - Reads the file, computes hashes, generates docstrings using the assistant, and potentially prompts for user approval before saving changes.\n\n3. **`filter_files_by_hash(...)`**:\n   - **Purpose**: Checks the SHA-256 hashes of files against a cache to identify which files need processing.\n   - **Arguments**:\n     - `file_paths`: List of paths to Python files.\n     - `repo_path`: The repository directory for relative path calculations.\n     - `cache`: Cached dictionary of file hashes.\n   - **Returns**: A list of file paths that have changed and need processing.\n\n4. **`upload_files_to_openai(...)`**:\n   - **Purpose**: Uploads files to OpenAI and retrieves their corresponding file IDs.\n   - **Arguments**:\n     - `file_paths`: List of paths of Python files to upload.\n   - **Returns**: A list of file IDs from OpenAI after successful uploads.\n\n5. **`create_github_pr(...)`** (from `docstring_ai.lib.github_utils`):\n   - **Purpose**: Manages the creation of GitHub pull requests for the processed files.\n   - **Arguments**: Various arguments related to the repository and branch handling.\n\n### Logging and Error Handling\n\n- The module integrates logging extensively, tracking the flow of execution and reporting errors that occur throughout the file processing and interaction with external APIs. \n\n### Dependencies\n\nThe module relies on external libraries and components:\n- **OpenAI**: For generating docstrings and managing file uploads.\n- **ChromaDB**: To store and retrieve context information efficiently.\n- **GitHub API**: For managing interactions with GitHub repositories.\n- **Pydantic**: For validating the structure of data, especially in the context of the `PythonFile` class.\n\n### Conclusion\n\nIn summary, this module serves as a powerful enhancement tool for Python code documentation practices, integrating AI for automated docstring generation, efficient resource handling through ChromaDB, and seamless submission of changes to version control platforms like GitHub. Its structure emphasizes modularity and reusability, making it suitable for adapting to further enhancements or integrations with additional tools."
  }
]