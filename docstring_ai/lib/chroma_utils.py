# Docstring generated by docstring-ai : http://github.com/ph-ausseil/docstring-ai
"""
This module facilitates the embedding and storage of Python files' content into a ChromaDB database. The primary functionalities focus on initializing a database client, managing collections (retrieving or creating them), embedding text documents, and storing relevant summaries and contexts for future retrieval.

Main Functionalities:
1. Database Initialization: Functions to establish a connection to ChromaDB.
2. Collection Management: Functions that handle the retrieval or creation of collections in ChromaDB.
3. Embedding and Storage: Read Python files, embed their contents, and store them in ChromaDB.
4. Context Retrieval: A function to query the database for relevant documents based on specific criteria.
5. Storing Class Summaries: Functions to embed class summaries and associate them with Python files.
6. Error Handling and Logging: Integrated logging for tracking operations and errors.
"""

import os
import openai
import logging
import chromadb
import logging
from chromadb.config import Settings
from chromadb.utils import embedding_functions
import tiktoken
from typing import List, Dict
from docstring_ai import EMBEDDING_MODEL
import traceback

def initialize_chroma() -> chromadb.Client:
    """
    Initialize ChromaDB client.

    This function establishes a connection to the ChromaDB server.

    Returns:
        chromadb.Client: A ChromaDB client instance connected to the server.

    Example:
        client = initialize_chroma()
    """
    client = chromadb.Client(Settings(
        chroma_server_host="localhost",
        chroma_server_http_port="8000"
    ))
    return client

def get_or_create_collection(client: chromadb.Client, collection_name: str) -> chromadb.Collection:
    """
    Retrieve an existing collection or create a new one.

    This function checks if a specified collection exists in ChromaDB and returns it.
    If the collection does not exist, it creates a new one.

    Args:
        client (chromadb.Client): The ChromaDB client used to interact with the database.
        collection_name (str): The name of the collection to retrieve or create.

    Returns:
        chromadb.Collection: The ChromaDB collection instance.

    Raises:
        Exception: If there is an issue retrieving or creating the collection.
    """
    existing_collections = client.list_collections()
    
    for collection in existing_collections:
        if collection.name == collection_name:
            logging.info(f"ChromaDB Collection '{collection_name}' found.")
            return client.get_collection(
                name=collection_name,
                embedding_function=embedding_functions.OpenAIEmbeddingFunction(
                    api_key=openai.api_key,
                    model_name=EMBEDDING_MODEL
                )
            )
    logging.debug(f"ChromaDB Collection '{collection_name}' not found. Creating a new one.")
    collection = client.create_collection(
        name=collection_name,
        embedding_function=embedding_functions.OpenAIEmbeddingFunction(
            api_key=openai.api_key,
            model_name=EMBEDDING_MODEL
        )
    )
    return collection

def embed_and_store_files(collection: chromadb.Collection, python_files: List[str], tags: Dict[str, str] = {}) -> None:
    """
    Embed each Python file and store it in ChromaDB.

    This function reads the contents of each specified Python file, embeds the content,
    and stores the embedded representations in the ChromaDB collection.

    Args:
        collection (chromadb.Collection): The ChromaDB collection where documents will be stored.
        python_files (List[str]): A list of file paths to the Python files to be embedded.

    Raises:
        Exception: If there's an error reading the files or adding them to ChromaDB.
    """
    ids = []
    documents = []
    metadatas = []
    for file_path in python_files:
        file_path = str(file_path)
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            doc_id = os.path.relpath(file_path)
            ids.append(doc_id)
            documents.append(content)
            metadatas.append({"file_path": file_path} | tags)
            logging.info(f"Prepared file for embedding: {file_path}")
        except Exception as e:
            logging.error(f"Error reading file {file_path}: {e}")

    # Validation
    if not (len(documents) == len(ids) == len(metadatas)):
        logging.error("Length mismatch between documents, ids, and metadatas.")
        return

    if any(not doc for doc in documents):
        logging.error("One or more documents are empty.")
        return

    if len(ids) != len(set(ids)):
        logging.error("Duplicate IDs found in the documents to be added.")
        return

    # Add to ChromaDB
    try:
        collection.add(
            documents=documents,
            ids=ids,
            metadatas=metadatas
        )
        logging.info(f"Embedded and stored {len(ids)} files in ChromaDB.")
    except Exception as e:
        logging.error(f"Error adding documents to ChromaDB: {e}")
        logging.error(traceback.format_exc())


def get_relevant_context(collection: chromadb.Collection, classes: List[str], max_tokens: int , where : str = None) -> str:
    """
    Retrieve relevant documents from ChromaDB based on class dependencies.

    This function fetches relevant document content from the specified collection
    while ensuring that the total token count does not exceed the specified maximum.

    Args:
        collection (chromadb.Collection): The ChromaDB collection to query.
        classes (Dict[str, List[str]]): A dictionary mapping class names to their dependencies.
        max_tokens (int): The maximum number of tokens allowed for the retrieved context.

    Returns:
        str: The accumulated context as a single string.

    Example:
        context = get_relevant_context(collection, classes, max_tokens)
    """
    try: 
        encoder = tiktoken.get_encoding("o200k_base")
        context = ""
        token_count = 0
        # Corrected join operation
        query = " ".join(classes)
        results = collection.query(
                query_texts=[query],
                n_results=5,
                where=where
            )
        for doc in results['documents'][0]:
            doc_tokens = len(encoder.encode(doc))
            if token_count + doc_tokens > max_tokens:
                logging.info("Reached maximum token limit for context.")
                return context
            context += doc + "\n\n"
            token_count += doc_tokens
        return context
    except Exception as e: 
        logging.error(f"Error guiding the prompt : {e}")


def store_class_summary(collection: chromadb.Collection, file_path: str, class_name: str, summary: str) -> None:
    """
    Store the class summary in ChromaDB for future context.

    This function embeds the provided summary for a specific class and stores it 
    in the specified ChromaDB collection, associating it with the respective 
    file path and class name.

    Args:
        collection (chromadb.Collection): The ChromaDB collection where the summary will be stored.
        file_path (str): The path to the file containing the class.
        class_name (str): The name of the class for which the summary is stored.
        summary (str): The summary text to be embedded and stored.

    Raises:
        Exception: If there's an error storing the class summary in ChromaDB.
    """
    try:
        doc_id = f"{file_path}::{class_name}"
        collection.add(
            documents=[summary],
            ids=[doc_id],
            metadatas=[{"file_path": file_path, "class_name": class_name}]
        )
        logging.info(f"Stored summary for class '{class_name}' in ChromaDB.")
    except Exception as e:
        logging.error(f"Error storing class summary for '{class_name}': {e}")
        logging.error(traceback.format_exc())
